{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Q1"
      ],
      "metadata": {
        "id": "QK-0syxkWi21"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   In this question we want to use POS-tagged training set to compute for each word the tag that maximizes $p(t|w)$.\n",
        "*   We will implement a simple tokenizer to deal with sentence boundaries.\n",
        "*   We start by assuming that all unknown words are NN and compute error rate on known and unknown words.\n",
        "*   Then write at least five rules to do a better job of tagging unknown words, and show the difference in error rates.\n"
      ],
      "metadata": {
        "id": "YX0LV_hrWPsG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lueYCsOI0WgG"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import math\n",
        "\n",
        "import nltk\n",
        "nltk.download('brown')\n",
        "from nltk.corpus import brown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dict(_samples):\n",
        "    \"\"\"\n",
        "    Generate a dictionary that captures the count of each (word, tag) combination from a list of samples.\n",
        "\n",
        "    Args:\n",
        "    _samples (list): List of tuples containing (word, tag) pairs.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary where keys are words and values are lists of dictionaries with 'tag' and 'count' keys.\n",
        "          Each dictionary in the list represents a unique tag associated with the word and its count.\n",
        "    \"\"\"\n",
        "\n",
        "    '''\n",
        "    Example:\n",
        "      _samples = [('apple', 'fruit'), ('banana', 'fruit'), ('apple', 'fruit'), ('apple', 'color'), ('banana', 'color')]\n",
        "      After calling generate_dict(_samples), the expected output would be:\n",
        "      {\n",
        "          'apple': [\n",
        "              {'tag': 'fruit', 'count': 2},\n",
        "              {'tag': 'color', 'count': 1}\n",
        "          ],\n",
        "          'banana': [\n",
        "              {'tag': 'fruit', 'count': 1},\n",
        "              {'tag': 'color', 'count': 1}\n",
        "          ]\n",
        "      }\n",
        "      This represents that 'apple' appeared twice with the tag 'fruit' and once with the tag 'color',\n",
        "      while 'banana' appeared once with both 'fruit' and 'color' tags.\n",
        "\n",
        "    '''\n",
        "\n",
        "    dictionary = {}\n",
        "\n",
        "\n",
        "    ## Your code here\n",
        "    # create the dictionary described in the comments\n",
        "\n",
        "    for sample in _samples:\n",
        "        if sample[0] not in dictionary:\n",
        "            dictionary.update({sample[0]: [{'tag': sample[1], 'count': 1}]})\n",
        "        else:\n",
        "            matched = False\n",
        "            for item in dictionary[sample[0]]:\n",
        "                if item['tag'] == sample[1]:\n",
        "                    item['count'] += 1\n",
        "                    matched = True\n",
        "                    break\n",
        "            if not matched:\n",
        "              dictionary[sample[0]].append({'tag': sample[1], 'count': 1})\n",
        "\n",
        "    ## End Code\n",
        "    def get_tag_counts(subitem):\n",
        "        return subitem['count']\n",
        "\n",
        "    for item in dictionary:\n",
        "        sorted(dictionary[item], key=get_tag_counts, reverse=True)\n",
        "\n",
        "    return dictionary"
      ],
      "metadata": {
        "id": "9ppIGG8ZWv1c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tag(_test_set, _tag_dict):\n",
        "    \"\"\"\n",
        "    Predicts the tags for a given test set of words based on a provided tag dictionary.\n",
        "\n",
        "    Args:\n",
        "    _test_set (list): A list of tuples containing (word, true_tag) pairs to be predicted.\n",
        "    _tag_dict (dict): A dictionary containing words as keys and lists of dictionaries with 'tag' and 'count' keys as values.\n",
        "\n",
        "    Returns:\n",
        "    float: The accuracy of the predictions, calculated as the ratio of correct predictions to the total number of predictions.\n",
        "\n",
        "    Comments:\n",
        "    - For unknown words, 'NN' (noun) tag is assigned.\n",
        "    - Tags are assigned based on the highest count for known words.\n",
        "      - If there are more than 1 tag for a given word, the tag with the highest count is chosen.\n",
        "      - If there is only 1 tag available, it is returned directly.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    accuracy = 0\n",
        "    for item in _test_set:\n",
        "        word = item[0]\n",
        "        true_tag = item[1]\n",
        "        if word in _tag_dict:\n",
        "            # assign tag with the highest count\n",
        "            # if there are more than 1 tag for a given word\n",
        "            # return the only tag if there is just 1 tag\n",
        "            prediction = _tag_dict[word][0]['tag']\n",
        "        else:\n",
        "            # assign noun tag to unknown words\n",
        "            prediction = 'NN'\n",
        "        if prediction == true_tag: accuracy += 1\n",
        "\n",
        "    accuracy /= len(_test_set)\n",
        "    print(f\"Assuming that all unknown words are NN\")\n",
        "    print(f\">> accuracy: {accuracy}\")\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "C-wu5AVoX_rN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tag_with_improvements(_test_set, _tag_dict):\n",
        "    \"\"\"\n",
        "    Predicts the tags for a given test set of words based on a provided tag dictionary, with additional rules for unknown words.\n",
        "\n",
        "    Args:\n",
        "    _test_set (list): A list of tuples containing (word, true_tag) pairs to be predicted.\n",
        "    _tag_dict (dict): A dictionary containing words as keys and lists of dictionaries with 'tag' and 'count' keys as values.\n",
        "\n",
        "    Returns:\n",
        "    float: The accuracy of the predictions, calculated as the ratio of correct predictions to the total number of predictions.\n",
        "\n",
        "    Comments:\n",
        "    - For unknown words, 'NN' (noun) tag is initially assigned.\n",
        "    - Additional rules are applied to analyze unknown words and assign more specific tags based on patterns observed in the word:\n",
        "        - 'VBG' (verb, gerund) for words ending in 'ing'\n",
        "        - 'NP$' (noun, possessive) for words ending in \"'s\"\n",
        "        - 'NNS' (noun, plural) for words ending in 's'\n",
        "        - 'RB' (adverb) for words ending in 'ly'\n",
        "        - 'VBN' (verb, past participle) for words ending in 'ed'\n",
        "        - 'JJ' (adjective) for words matching certain patterns like 'ble', 'ish', 'ful', etc.\n",
        "        - 'CD' (cardinal numeral) for numeric strings\n",
        "        - 'NP' (noun, proper singular) for capitalized words\n",
        "    \"\"\"\n",
        "\n",
        "    ## Your code here\n",
        "    accuracy = 0\n",
        "    for item in _test_set:\n",
        "        word = item[0]\n",
        "        true_tag = item[1]\n",
        "        if word in _tag_dict:\n",
        "            prediction = _tag_dict[word][0]['tag']\n",
        "        else:\n",
        "            prediction = 'NN'\n",
        "\n",
        "            # additional rules to analyze unknown words\n",
        "            if re.match('.*ing$', word):\n",
        "                prediction = 'VBG'\n",
        "            elif re.match(\".*'s$\", word):\n",
        "                prediction = 'NP$'\n",
        "            elif re.match('.+s$', word):\n",
        "                prediction = 'NNS'\n",
        "            elif re.match('.+ly$', word):\n",
        "                prediction = 'RB'\n",
        "            elif re.match('.+ed$', word):\n",
        "                prediction = 'VBN'\n",
        "            elif re.match('.+(ble|ish|ful|can|ky|dy|ic|ous|ern)$', word):\n",
        "                prediction = 'JJ'\n",
        "            elif re.match('\\d+(,)?\\d*(\\.\\d+)?$', word):\n",
        "                prediction = 'CD'\n",
        "            elif re.match('[A-Z][a-z]+', word):\n",
        "                prediction = 'NP'\n",
        "\n",
        "        if prediction == true_tag: accuracy += 1\n",
        "    ## End Code\n",
        "    accuracy /= len(_test_set)\n",
        "    print(f\"With additional rules for unknown words\")\n",
        "    print(f\">> accuracy: {accuracy}\")\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "SgXAgTDrcbYl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CORPUS = brown.tagged_words(categories='news')\n",
        "CORPUS_SIZE = len(brown.tagged_words(categories='news'))\n",
        "\n",
        "CUT_OFF = math.floor(CORPUS_SIZE * 0.75)\n",
        "\n",
        "# section off training and testing lists from corpus\n",
        "training_list = CORPUS[:CUT_OFF]\n",
        "testing_list = CORPUS[CUT_OFF:]\n",
        "\n",
        "# duplicates are ignored in sets\n",
        "training_set = set(training_list)\n",
        "testing_set = set(testing_list)\n",
        "intersection = training_set.intersection(testing_set)\n",
        "\n",
        "print(f\"length of training set:     {len(training_list)}\")\n",
        "print(f\"length of testing set:      {len(testing_list)}\")\n",
        "\n",
        "# uncomment to see how much the training set and testing set overlap\n",
        "# print(f\"intersection:               {len(intersection)}\")\n",
        "\n",
        "# uncomment to survey tagged corpus\n",
        "# print(training_set)\n",
        "\n",
        "tag_dict = generate_dict(training_list)\n",
        "accurary_base = predict_tag(testing_list, tag_dict)\n",
        "accurary_impr = predict_tag_with_improvements(testing_list, tag_dict)\n",
        "delta = math.floor((accurary_impr - accurary_base) * len(testing_list))\n",
        "print(f\"{delta} more words got correctly classified.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P6OX_pEh_tZ",
        "outputId": "987710d2-2bd4-4276-8598-672d31ff8a47"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of training set:     75415\n",
            "length of testing set:      25139\n",
            "Assuming that all unknown words are NN\n",
            ">> accuracy: 0.8184096423883209\n",
            "With additional rules for unknown words\n",
            ">> accuracy: 0.8638370659135208\n",
            "1142 more words got correctly classified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J0EY8XNVirmv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}